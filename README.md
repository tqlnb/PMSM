# æ”¶é›†æ•°æ®

## å®éªŒè®¾å¤‡
ä½¿ç”¨STM32F103zeT6å¼€å‘æ¿ï¼ŒST Motor Control Workbench5.4.4ç”Ÿæˆæ§åˆ¶ä»£ç ã€‚è®¾ç½®å¦‚ä¸‹

![image](https://github.com/user-attachments/assets/08bec522-4143-43ff-b24e-d2ae0bd4d08b)

![image](https://github.com/user-attachments/assets/153a7374-4448-45fd-8eb1-777de85c50ee)

![image](https://github.com/user-attachments/assets/84c8595d-dde3-4558-af81-c78906c7c023)

![image](https://github.com/user-attachments/assets/f16f6fbc-3e02-487f-9d1f-38231389ba34)

![image](https://github.com/user-attachments/assets/3f6a69eb-82d3-4c33-8ad1-91628c09e893)

![image](https://github.com/user-attachments/assets/ae368ec2-7aed-4c2c-af9a-ca8e48e9d180)

![image](https://github.com/user-attachments/assets/40a3bbf2-836e-4b66-b949-dc2e9c304737)

![image](https://github.com/user-attachments/assets/e712c63f-9519-4a45-aab2-ef75543f357f)

![image](https://github.com/user-attachments/assets/542b925e-afb2-42a8-8527-cbb0b3dba326)

![image](https://github.com/user-attachments/assets/8e8eb12b-c2a6-4208-b6d6-a2fffcda944c)

![image](https://github.com/user-attachments/assets/7fe9bf21-ec6b-4e85-9e9b-af93a057b4cc)

![image](https://github.com/user-attachments/assets/514bdded-1136-4ade-a60b-ead7902d3315)

![image](https://github.com/user-attachments/assets/a50f9118-5142-47a6-ba26-f317753814ee)

![image](https://github.com/user-attachments/assets/923f8dd5-3ece-4b8e-87a6-ce8aef01ca02)

![image](https://github.com/user-attachments/assets/62ce0629-28df-415e-b3a8-f3ca15e7eb48)

![image](https://github.com/user-attachments/assets/1163d469-efe9-496b-a339-6b07f149086e)

![image](https://github.com/user-attachments/assets/bcd76320-a1fe-4040-ab3b-4f856445d42d)

![image](https://github.com/user-attachments/assets/7c1ee390-3220-42e1-aa50-38ecda73dd55)

ç”Ÿæˆä»£ç ç„¶åä¿®æ”¹main.cæ–¹æ³•åŠ ä¸Šä¸²å£æ•°æ®ä¼ è¾“ï¼ˆid,iq,ud,uqï¼‰

```c
/**
  * @brief  The application entry point.
  * @retval int
  */
int main(void)
{
  /* USER CODE BEGIN 1 */

  /* USER CODE END 1 */

  /* MCU Configuration--------------------------------------------------------*/

  /* Reset of all peripherals, Initializes the Flash interface and the Systick. */
  HAL_Init();

  /* USER CODE BEGIN Init */

  /* USER CODE END Init */

  /* Configure the system clock */
  SystemClock_Config();

  /* USER CODE BEGIN SysInit */

  /* USER CODE END SysInit */

  /* Initialize all configured peripherals */
  MX_GPIO_Init();
  MX_DMA_Init();
  MX_ADC1_Init();
  MX_ADC2_Init();
  MX_TIM1_Init();
  MX_TIM4_Init();
  MX_USART1_UART_Init();
  MX_MotorControl_Init();

  /* Initialize interrupts */
  MX_NVIC_Init();
  /* USER CODE BEGIN 2 */

  /* USER CODE END 2 */

  /* Infinite loop */
  /* USER CODE BEGIN WHILE */
  // è·å–FOCVars_tç»“æ„ä½“
  FOCVars_t* vars = GetFOCVars(0);
  char buffer[64];
  while (1)
  {
    /* USER CODE END WHILE */
    // FOCVars_t* vars = GetFOCVars(0);
    // HAL_UART_Transmit(&huart1, (uint8_t*)"Hello World!\r\n", 14, 1000); 
    // è·å–ç”µæµå€¼
    int16_t current_id = vars->Iqd.d;
    int16_t current_iq = vars->Iqd.q;
    //è·å–ç”µå‹å€¼
    int16_t voltage_d = vars->Vqd.d;
    int16_t voltage_q = vars->Vqd.q;
    // å‘é€
    sprintf(buffer, "id:%d,iq:%d,vd:%d,vq:%d\r\n", current_id, current_iq, voltage_d, voltage_q);
    HAL_UART_Transmit(&huart1, buffer, strlen(buffer), 1000); 
    HAL_Delay(20);
    /* USER CODE BEGIN 3 */
  }
  /* USER CODE END 3 */
}

```

## id,iq,ud,uqæ¥æº
åœ¨ç”µæœºæ§åˆ¶ä¸­ï¼Œ\(i_{uvw}\)ã€\(u_{uvw}\) æ˜¯æŒ‡å®šå­ä¸‰ç›¸ç”µæµå’Œç”µå‹ï¼Œ\(i_{d}\)ã€\(i_{q}\)ã€\(u_{d}\)ã€\(u_{q}\) æ˜¯åœ¨æ—‹è½¬åæ ‡ç³»ï¼ˆdqåæ ‡ç³»ï¼‰ä¸­çš„ç”µæµå’Œç”µå‹åˆ†é‡ã€‚å°†ä¸‰ç›¸åæ ‡ç³» (\(uvw\)) è½¬æ¢åˆ°ä¸¤ç›¸æ—‹è½¬åæ ‡ç³» (\(dq\))ï¼Œéœ€è¦è¿›è¡Œåæ ‡å˜æ¢ï¼Œè¿™åŒ…æ‹¬ **Clarkå˜æ¢** å’Œ **Parkå˜æ¢**ã€‚

ä»¥ä¸‹æ˜¯ä¸»è¦æ­¥éª¤ï¼š

---

1. **ä»ä¸‰ç›¸åæ ‡ç³»åˆ°ä¸¤ç›¸é™æ­¢åæ ‡ç³» - Clarkå˜æ¢**
Clarkå˜æ¢å°†ä¸‰ç›¸ä¿¡å·æŠ•å½±åˆ°ä¸€ä¸ªé™æ­¢çš„ä¸¤ç›¸å¹³é¢ä¸Šã€‚å‡è®¾ä¸‰ç›¸ç”µæµä¸º \(i_u\), \(i_v\), \(i_w\)ï¼Œæˆ‘ä»¬æœ‰ï¼š

![image](https://github.com/user-attachments/assets/2f6e830d-c8ad-49e4-8e78-9b89a562e11e)

è‹¥ä¸‰ç›¸ç”µæµæ»¡è¶³å¹³è¡¡ï¼ˆ\(i_u + i_v + i_w = 0\)ï¼‰ï¼Œä¸Šè¿°å…¬å¼å¯ä»¥ç®€åŒ–ä¸ºï¼š

![image](https://github.com/user-attachments/assets/d98e8954-3d83-4708-ad84-9b6db78f7e88)


åŒç†é€‚ç”¨äºç”µå‹ (\(u_u, u_v, u_w\))ã€‚


2. **ä»é™æ­¢åæ ‡ç³»åˆ°æ—‹è½¬åæ ‡ç³»ï¼ˆ\(dq\)ï¼‰ - Parkå˜æ¢**
Parkå˜æ¢å°† \(\alpha\beta\) åæ ‡ç³»ä¸­çš„é‡æŠ•å½±åˆ°æ—‹è½¬åæ ‡ç³» \(dq\)ã€‚æ—‹è½¬åæ ‡ç³»ä¸ç”µæœºè½¬å­çš„æ—‹è½¬ä½ç½®åŒæ­¥ï¼Œä½¿ç”¨è½¬å­ç£é“¾ä½ç½®è§’ \(\theta\) è¿›è¡Œå˜æ¢ï¼š


![image](https://github.com/user-attachments/assets/2b7db792-fb77-4dba-9257-699ce3cbef83)


å…¶ä¸­ï¼Œ\(\theta\) é€šå¸¸ç”±ç”µæœºæ§åˆ¶å™¨ä¸­çš„ä½ç½®ä¼ æ„Ÿå™¨ï¼ˆå¦‚ç¼–ç å™¨ï¼‰æˆ–è§‚æµ‹å™¨æä¾›ã€‚


3. **æ€»ç»“**
- Clarkå˜æ¢ï¼šå°†ä¸‰ç›¸ä¿¡å·æŠ•å½±åˆ°é™æ­¢çš„ \(\alpha\beta\) å¹³é¢ï¼›
- Parkå˜æ¢ï¼šå°†é™æ­¢çš„ \(\alpha\beta\) ä¿¡å·æŠ•å½±åˆ°æ—‹è½¬çš„ \(dq\) åæ ‡ç³»ï¼›
- \(i_d\)ã€\(i_q\) åˆ†åˆ«å¯¹åº”ç›´è½´ï¼ˆdè½´ï¼‰å’Œäº¤è½´ï¼ˆqè½´ï¼‰çš„ç”µæµåˆ†é‡ï¼Œé€šå¸¸ \(i_d\) ç”¨äºæ§åˆ¶ç£é“¾ï¼Œ\(i_q\) ç”¨äºæ§åˆ¶ç”µç£è½¬çŸ©ã€‚

å®Œæ•´æµç¨‹ä¸ºï¼š

![image](https://github.com/user-attachments/assets/7bfcceab-e41b-4f52-94ce-c144ff5139be)

## åœ¨ç”µæœºè¿è¡Œæ—¶ä½¿ç”¨javaç¨‹åºæ”¶é›†ä¸²å£æ•°æ®


1.é‡‡é›†ä¸²å£æ•°æ®
```java
package tql.test.test32;

import jssc.SerialPort;
import jssc.SerialPortEvent;
import jssc.SerialPortEventListener;
import jssc.SerialPortException;

import java.io.BufferedWriter;
import java.io.FileWriter;
import java.io.IOException;

public class SerialDataLogger {
    private static final String PORT_NAME = "COM5"; // ä¿®æ”¹ä¸ºå®é™…ä¸²å£åç§°
    private static final int BAUD_RATE = 115200;   // æ ¹æ®å®é™…è®¾ç½®æ³¢ç‰¹ç‡
    private static final String OUTPUT_FILE = "data_log.txt";
    private static BufferedWriter writer;

    public static void main(String[] args) throws IOException {
        SerialPort serialPort = new SerialPort(PORT_NAME);
        try {
            // æ‰“å¼€ä¸²å£
            serialPort.openPort();
            serialPort.setParams(
                BAUD_RATE,
                SerialPort.DATABITS_8,
                SerialPort.STOPBITS_1,
                SerialPort.PARITY_NONE
            );

            // æ·»åŠ ä¸²å£ç›‘å¬å™¨
            serialPort.addEventListener(new SerialPortEventListener() {

                {
                    try {
                        writer = new BufferedWriter(new FileWriter(OUTPUT_FILE, true));
                    } catch (IOException e) {
                        e.printStackTrace();
                    }
                }

                @Override
                public void serialEvent(SerialPortEvent event) {
                    if (event.isRXCHAR() && event.getEventValue() > 0) {
                        try {

                            String data = serialPort.readString(event.getEventValue());
                            //System.out.println(data);
                            if(data.startsWith("id")) {
                                if(!data.endsWith("\n")) {
                                    data = data + "\n";
                                }
                                String s = System.currentTimeMillis() + ",Received:" + data;
                                System.out.print(s);

                                if (writer != null) {
                                    writer.write(s);
                                    writer.flush();
                                }
                            }
                        } catch (SerialPortException | IOException e) {
                            e.printStackTrace();
                        }
                    }
                }
            });
            while (true) {
                Thread.sleep(1000);
            }
        } catch (SerialPortException e) {
            e.printStackTrace();
        } catch (InterruptedException e) {
            throw new RuntimeException(e);
        } finally {
            if (writer != null) {
                writer.close();
            }
        }
    }
}

```

2.å¤„ç†æ•°æ®ï¼Œæ”¾åˆ°csvæ–‡ä»¶

```java
package tql.test.test32;

import java.io.*;
import java.util.Date;
import java.util.regex.*;

public class DataProcessor {
    private static final String INPUT_FILE = "data_log.txt";  // åŸå§‹æ•°æ®æ–‡ä»¶è·¯å¾„
    private static final String OUTPUT_FILE = "id_iq_vd_vq.csv"; // è¾“å‡ºæ–‡ä»¶è·¯å¾„

    public static void main(String[] args) {
        try (BufferedReader reader = new BufferedReader(new FileReader(INPUT_FILE));
             BufferedWriter writer = new BufferedWriter(new FileWriter(OUTPUT_FILE))) {
            
            // å†™å…¥è¡¨å¤´
            writer.write("time,id,iq,vd,vq");
            writer.newLine();
            int idValue = 0;
            int iqValue = 0;
            int vdValue = 0;
            int vqValue = 0;
            float id_real = 0;
            float iq_real = 0;
            float vd_real = 0;
            float vq_real = 0;
            Date date ;


            String line;
            while ((line = reader.readLine()) != null) {
                // åŒ¹é…æ—¶é—´æˆ³å’Œæ•°æ®
                Pattern pattern = Pattern.compile("(-?\\d+),Received:id:(\\d+),iq:(-?\\d+),vd:(-?\\d+), vq:(-?\\d+)");
                Matcher matcher = pattern.matcher(line);

                if (matcher.find()) {
                    // æå–æ•°æ®
                    String time = matcher.group(1);
                    String id = matcher.group(2);
                    String iq = matcher.group(3);
                    String vd = matcher.group(4);
                    String vq = matcher.group(5);
                    // å¯¹æ•°æ®è¿›è¡Œå¤„ç†
                    date = new Date(Long.parseLong(time));
                    idValue = Integer.parseInt(id);
                    iqValue = Integer.parseInt(iq);
                    vdValue = Integer.parseInt(vd);
                    vqValue = Integer.parseInt(vq);

                    id_real = convertToRealValue(idValue, 60);
                    iq_real = convertToRealValue(iqValue, 60);
                    vd_real = convertToRealValue(vdValue, 60);
                    vq_real = convertToRealValue(vqValue, 60);

                    // å†™å…¥ CSV æ ¼å¼
                    //writer.write(String.join(",", time, id, iq, vd, vq));
                    java.text.SimpleDateFormat dateFormat = new java.text.SimpleDateFormat("yyyy-MM-dd HH:mm:ss");
                    writer.write(String.join(",", dateFormat.format(date), String.valueOf(id_real), String.valueOf(iq_real), String.valueOf(vd_real), String.valueOf(vq_real)));
                    //writer.write(String.join(",", time, String.valueOf(id_real), String.valueOf(iq_real), String.valueOf(vd_real), String.valueOf(vq_real)));
                    writer.newLine();
                }
            }
            
            System.out.println("Data processing complete. Output saved to: " + OUTPUT_FILE);
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    private static float convertToRealValue(int value, float maxValue) {
        return value / 32767.0f * maxValue;
    }
}
```

3.æ‰­çŸ©ä¼ æ„Ÿå™¨çš„æ•°æ®ï¼Œ.xlsæ–‡ä»¶ï¼ˆå…¶å®æ˜¯æ–‡æœ¬æ–‡ä»¶ï¼‰ï¼Œå¤„ç†ä¸º.csvæ–‡ä»¶

```java
package tql.test.test32;

import java.io.*;
import java.text.ParseException;
import java.text.SimpleDateFormat;

public class TextToCSV {
    public static void main(String[] args) {
        // è¾“å…¥æ–‡ä»¶è·¯å¾„
        String inputFilePath = "myexcel.txt";
        // è¾“å‡º CSV æ–‡ä»¶è·¯å¾„
        String outputFilePath = "torque_speed_time.csv";

        try (BufferedReader reader = new BufferedReader(new FileReader(inputFilePath));
             BufferedWriter writer = new BufferedWriter(new FileWriter(outputFilePath))) {

            // å†™å…¥ CSV æ–‡ä»¶è¡¨å¤´
            writer.write("torque,speed,time\n");

            String line;
            SimpleDateFormat inputFormat = new SimpleDateFormat("yyyy/MM/dd HH:mm:ss");
            SimpleDateFormat outputFormat = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");

            while ((line = reader.readLine()) != null) {
                // è·³è¿‡ç©ºè¡Œ
                if (line.trim().isEmpty()) continue;

                // å°†åˆ¶è¡¨ç¬¦æ›¿æ¢ä¸ºé€—å·
                String[] parts = line.split("\t");
                if (parts.length == 3) {
                    String torque = parts[0];
                    String speed = parts[1];
                    String time = parts[2];

                    try {
                        // è½¬æ¢æ—¶é—´æ ¼å¼
                        time = outputFormat.format(inputFormat.parse(time));
                    } catch (ParseException e) {
                        System.err.println("æ—¶é—´æ ¼å¼è§£æé”™è¯¯: " + time);
                    }

                    String csvLine = torque + "," + speed + "," + time;
                    writer.write(csvLine + "\n");
                }
            }

            System.out.println("CSV æ–‡ä»¶å·²ç”Ÿæˆ: " + outputFilePath);

        } catch (IOException e) {
            System.err.println("æ–‡ä»¶è¯»å†™é”™è¯¯: " + e.getMessage());
        }
    }
}
```

4.æ±‡æ€»æ•°æ®ï¼Œä½¿ç”¨python

```python
import pandas as pd

# è¯»å–ä¸¤ä¸ªCSVæ–‡ä»¶
high_freq_df = pd.read_csv('data/id_iq_vd_vq.csv')  
low_freq_df = pd.read_csv('data/torque_speed_time.csv')  

# è®¾ç½®æ—¶é—´åˆ—ä¸ºç´¢å¼•
high_freq_df.set_index('time', inplace=True)
low_freq_df.set_index('time', inplace=True)

# å°†æ—¶é—´åˆ—è½¬æ¢ä¸º datetime ç±»å‹
high_freq_df.index = pd.to_datetime(high_freq_df.index)
low_freq_df.index = pd.to_datetime(low_freq_df.index)

# å¤„ç†é‡å¤çš„æ—¶é—´æˆ³ï¼Œé€šè¿‡æ·»åŠ æ¯«ç§’æ¥åŒºåˆ†
high_freq_df['unique_time'] = high_freq_df.index
low_freq_df['unique_time'] = low_freq_df.index

# ä¸ºé‡å¤çš„æ—¶é—´æˆ³æ·»åŠ æ¯«ç§’ä¿¡æ¯
def add_milliseconds_to_duplicates(df):
    df['time_ms'] = df.groupby(df['unique_time']).cumcount()  # è®¡ç®—é‡å¤æ—¶é—´æˆ³çš„åºå·
    df['unique_time'] = df['unique_time'].dt.strftime('%Y-%m-%d %H:%M:%S') + '.' + df['time_ms'].astype(str).str.zfill(3)  # å°†æ¯«ç§’åŠ åˆ°æ—¶é—´æˆ³ä¸­
    df.drop(columns=['time_ms'], inplace=True)
    return df

high_freq_df = add_milliseconds_to_duplicates(high_freq_df)
low_freq_df = add_milliseconds_to_duplicates(low_freq_df)

# è®¾ç½®æ–°çš„å”¯ä¸€æ—¶é—´åˆ—ä¸ºç´¢å¼•
high_freq_df.set_index('unique_time', inplace=True)
low_freq_df.set_index('unique_time', inplace=True)

# æ‰¾åˆ°å…±åŒçš„æ—¶é—´èŒƒå›´
common_index = high_freq_df.index.intersection(low_freq_df.index)

# å¯¹ä½é¢‘æ•°æ®è¿›è¡Œçº¿æ€§æ’å€¼
low_freq_df_interp = low_freq_df.reindex(high_freq_df.index).interpolate(method='linear')

# åˆå¹¶æ•°æ®
merged_df = pd.concat([high_freq_df, low_freq_df_interp], axis=1)

# ä¿å­˜åˆå¹¶åçš„æ•°æ®
merged_df.to_csv('data/merged.csv')  # ä¿å­˜åˆå¹¶åçš„æ•°æ®åˆ°æ–‡ä»¶
```

## æ•°æ®å›¾åƒ

**ç½‘ä¸Šçš„æ ‡å‡†æ•°æ®**


![image](https://github.com/user-attachments/assets/a68de9c4-76f3-43c1-b339-afbafed0d674)

**æˆ‘çš„æ•°æ®**


![image](https://github.com/user-attachments/assets/e5aa61bb-fefa-4441-8245-3e61f61a14e8)


![image](https://github.com/user-attachments/assets/54886d8f-3c1b-4138-a088-e86622e407f5)


![image](https://github.com/user-attachments/assets/47f666d0-4167-4843-a064-95c7e00dcfab)


![image](https://github.com/user-attachments/assets/0e9ce2b5-a69a-4711-9bca-4012370951df)


![image](https://github.com/user-attachments/assets/c9d62080-a222-454a-a478-2e3af19a8e55)


# è®­ç»ƒçš„å°è¯•
## 1.ä½¿ç”¨ä¸¤å±‚å…¨è¿æ¥å±‚ï¼Œè¾“å…¥ä¸ºï¼ˆid,iq,vd,vqï¼‰,è¾“å‡ºä¸º(speed,torque)

```python
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# Load the dataset
df = pd.read_csv('data/merged.csv')

# Features and target
features = ['iq', 'id', 'vd', 'vq']
target = ['torque', 'speed']

# Prepare data å‡†å¤‡æ•°æ®
X = df[features].values
y = df[target].values

# Normalize data
scaler_X = StandardScaler()
scaler_y = StandardScaler()
X_scaled = scaler_X.fit_transform(X)
y_scaled = scaler_y.fit_transform(y)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)

# Convert to PyTorch tensors
X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train, dtype=torch.float32)
X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
y_test_tensor = torch.tensor(y_test, dtype=torch.float32)


# Define a simple feedforward neural network
class PINN(nn.Module):
    def __init__(self):
        super(PINN, self).__init__()
        self.fc1 = nn.Linear(4, 64)
        self.fc2 = nn.Linear(64, 64)
        self.fc3 = nn.Linear(64, 2)

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        x = self.fc3(x)
        return x


# Initialize model, loss function, and optimizer
model = PINN()
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Training loop
num_epochs = 1000
for epoch in range(num_epochs):
    model.train()

    # Forward pass
    outputs = model(X_train_tensor)
    loss = criterion(outputs.squeeze(), y_train_tensor)

    # Backward pass and optimization
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    if (epoch + 1) % 10 == 0:
        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')

# Evaluate the model
model.eval()
with torch.no_grad():
    test_outputs = model(X_test_tensor)
    test_loss = criterion(test_outputs.squeeze(), y_test_tensor)
    print(f'Test Loss: {test_loss.item():.4f}')

# Inverse transform for original scale
y_pred = scaler_y.inverse_transform(test_outputs.numpy())
y_true = scaler_y.inverse_transform(y_test_tensor.numpy())

# You can add more evaluations, such as computing R^2 score or visualizing results
from sklearn.metrics import mean_squared_error, r2_score

# Compute MSE and R2 score
mse = mean_squared_error(y_true, y_pred)
r2 = r2_score(y_true, y_pred)

print(f'Test Mean Squared Error: {mse:.4f}')
print(f'Test R^2 Score: {r2:.4f}')

# Compute residuals
residuals = np.abs(y_true - y_pred)

import matplotlib.pyplot as plt

# Plot residuals
plt.figure(figsize=(12, 6))
plt.hist(residuals.flatten(), bins=50, edgecolor='k', alpha=0.7)
plt.xlabel('Residuals')
plt.ylabel('Frequency')
plt.title('Residuals Distribution')
plt.show()

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.hist(y_train.flatten(), bins=30, alpha=0.7, label='Train')
plt.hist(y_test.flatten(), bins=30, alpha=0.7, label='Test')
plt.legend()
plt.title("Distribution of Target Values")
plt.subplot(1, 2, 2)
plt.boxplot([y_train.flatten(), y_test.flatten()], labels=["Train", "Test"])
plt.title("Boxplot of Target Values")
plt.show()

```

è¾“å‡º

```

Epoch [10/1000], Loss: 0.9219
Epoch [20/1000], Loss: 0.7748
Epoch [30/1000], Loss: 0.6301
...
Epoch [510/1000], Loss: 0.0953
Epoch [520/1000], Loss: 0.0947
Epoch [530/1000], Loss: 0.0941
...
Epoch [980/1000], Loss: 0.0772
Epoch [990/1000], Loss: 0.0769
Epoch [1000/1000], Loss: 0.0766
Test Loss: 0.2169
Test Mean Squared Error: 3613.3276
Test R^2 Score: 0.4504


----------------------åˆ†ç•Œçº¿ï¼Œä¸Šé¢æ˜¯æˆ‘çš„æ•°æ®ï¼Œä¸‹é¢æ˜¯ç½‘ä¸Šçš„æ•°æ®

Epoch [10/100], Loss: 0.6394
Epoch [20/100], Loss: 0.3311
Epoch [30/100], Loss: 0.1319
Epoch [40/100], Loss: 0.0442
Epoch [50/100], Loss: 0.0216
Epoch [60/100], Loss: 0.0120
Epoch [70/100], Loss: 0.0089
Epoch [80/100], Loss: 0.0063
Epoch [90/100], Loss: 0.0053
Epoch [100/100], Loss: 0.0047
Test Loss: 0.0046
Test Mean Squared Error: 27.6074
Test R^2 Score: 0.9954

```

ç½‘ä¸Šçš„
![image](https://github.com/user-attachments/assets/332a2356-bcac-4ca0-8bbd-d88232852519)

![image](https://github.com/user-attachments/assets/d8c5130b-ad98-4f3a-b7f8-d3b5cb970c68)

æˆ‘çš„
![image](https://github.com/user-attachments/assets/79614e70-1dee-4d60-8f0f-9a33f4bdcd27)

![image](https://github.com/user-attachments/assets/04112950-438d-43cb-925f-ee67e35dd4b9)

### åˆ†æç»“æœ
ä»è¿™äº›æµ‹è¯•ç»“æœæ¥çœ‹ï¼Œä½ çš„æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„æ€§èƒ½å¯ä»¥ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢åˆ†æï¼š

1. **Test Loss (æµ‹è¯•æŸå¤±)**: 
   - **å€¼ï¼š0.2117**  
   è¿™æ˜¯æ¨¡å‹çš„æŸå¤±å‡½æ•°å€¼ï¼Œå…·ä½“å–å†³äºä½ æ‰€ä½¿ç”¨çš„æŸå¤±å‡½æ•°ç±»å‹ï¼ˆä¾‹å¦‚å‡æ–¹è¯¯å·® MSE æˆ–äº¤å‰ç†µï¼‰ã€‚æŸå¤±è¶Šå°ï¼Œè¡¨æ˜æ¨¡å‹çš„é¢„æµ‹å€¼ä¸çœŸå®å€¼ä¹‹é—´çš„è¯¯å·®è¶Šå°ã€‚å½“å‰æŸå¤±å€¼å¹¶ä¸ç®—é«˜ï¼Œä½†è¿˜éœ€è¦ç»“åˆç›®æ ‡ä»»åŠ¡å’Œæ•°æ®èŒƒå›´è¿›è¡Œåˆ¤æ–­ã€‚

2. **Test Mean Squared Error (æµ‹è¯•å‡æ–¹è¯¯å·®)**:
   - **å€¼ï¼š3579.9895**  
   å‡æ–¹è¯¯å·®åæ˜ äº†æ¨¡å‹é¢„æµ‹å€¼ä¸çœŸå®å€¼çš„å¹³å‡åå·®çš„å¹³æ–¹ã€‚è¾ƒé«˜çš„å‡æ–¹è¯¯å·®ï¼ˆå¦‚è¿™é‡Œçš„3579.99ï¼‰è¡¨æ˜é¢„æµ‹è¯¯å·®è¾ƒå¤§ã€‚è¿™ä¸ªå€¼éœ€è¦ç»“åˆä½ çš„ç›®æ ‡å˜é‡çš„æ•°å€¼èŒƒå›´è¿›è¡Œåˆ¤æ–­ï¼Œä¾‹å¦‚ï¼Œå¦‚æœç›®æ ‡å˜é‡å€¼é€šå¸¸åœ¨æ•°åƒæˆ–æ›´é«˜çš„èŒƒå›´å†…ï¼Œé‚£ä¹ˆè¿™ä¸ªè¯¯å·®å¯èƒ½è¿˜èƒ½æ¥å—ï¼›å¦‚æœèŒƒå›´è¾ƒå°ï¼Œåˆ™è¯´æ˜æ¨¡å‹éœ€è¦æ”¹è¿›ã€‚

3. **Test RÂ² Score (æµ‹è¯• RÂ² åˆ†æ•°)**:
   - **å€¼ï¼š0.4591**  
   RÂ² åˆ†æ•°æ˜¯è¡¡é‡æ¨¡å‹æ‹Ÿåˆä¼˜åº¦çš„æŒ‡æ ‡ï¼Œå–å€¼èŒƒå›´ä¸º -âˆ åˆ° 1ï¼š
     - **1** è¡¨ç¤ºæ¨¡å‹å®Œç¾æ‹Ÿåˆæ•°æ®ã€‚
     - **0** è¡¨ç¤ºæ¨¡å‹é¢„æµ‹èƒ½åŠ›ä¸ç®€å•çš„å‡å€¼é¢„æµ‹ä¸€æ ·å·®ã€‚
     - **è´Ÿå€¼** è¡¨ç¤ºæ¨¡å‹ç”šè‡³æ¯”å‡å€¼é¢„æµ‹æ›´å·®ã€‚
     
   å½“å‰ RÂ² å€¼ä¸º 0.4591ï¼Œè¡¨æ˜æ¨¡å‹èƒ½å¤Ÿè§£é‡Š 45.91% çš„æ•°æ®æ–¹å·®ï¼Œè¯´æ˜æ¨¡å‹æœ‰ä¸€å®šçš„é¢„æµ‹èƒ½åŠ›ï¼Œä½†æ€§èƒ½å°šæœªè¾¾åˆ°ç†æƒ³æ°´å¹³ã€‚

## ä½¿ç”¨ç®€å•çš„PINN

å°†æ‰­çŸ©æ–¹ç¨‹å’Œé€Ÿåº¦æ–¹ç¨‹åŠ å…¥æŸå¤±å‡½æ•°

![image](https://github.com/user-attachments/assets/89719b3c-bea5-4195-bd33-e2df692be7a5)

```python
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, r2_score

# åŠ è½½æ•°æ®é›†
df = pd.read_csv('data/merged.csv')

# ç‰¹å¾å’Œç›®æ ‡
features = ['iq', 'id', 'vd', 'vq']
target = ['torque', 'speed']

# å‡†å¤‡æ•°æ®
X = df[features].values
y = df[target].values

# æ•°æ®å½’ä¸€åŒ–
scaler_X = StandardScaler()
scaler_y = StandardScaler()
X_scaled = scaler_X.fit_transform(X)
y_scaled = scaler_y.fit_transform(y)

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y_scaled, test_size=0.2, random_state=42
)

# è½¬æ¢ä¸ºPyTorchå¼ é‡
X_train_tensor = torch.tensor(X_train, dtype=torch.float32, requires_grad=True)
y_train_tensor = torch.tensor(y_train, dtype=torch.float32)
X_test_tensor = torch.tensor(X_test, dtype=torch.float32, requires_grad=True)
y_test_tensor = torch.tensor(y_test, dtype=torch.float32)

# å®šä¹‰PINNæ¨¡å‹
class PINN(nn.Module):
    def __init__(self):
        super(PINN, self).__init__()
        self.fc1 = nn.Linear(4, 64)
        self.fc2 = nn.Linear(64, 64)
        self.fc3 = nn.Linear(64, 2)

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        x = self.fc3(x)
        return x

# åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
model = PINN()
mse_loss = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# ç”µæœºç‰©ç†å‚æ•°ï¼ˆæ ¹æ®æä¾›çš„æ•°æ®ï¼‰
K_t = 0.059      # è½¬çŸ©å¸¸æ•° (Nm/A)
J = 0.08 * 1e-4  # è½¬åŠ¨æƒ¯é‡ (kgÂ·mÂ²) â€”â€” 0.08 kgÂ·cmÂ² è½¬æ¢ä¸º kgÂ·mÂ²
lambda_phys = 1e-3  # ç‰©ç†æŸå¤±æƒé‡

# è®­ç»ƒå¾ªç¯
num_epochs = 1000
for epoch in range(num_epochs):
    model.train()
    optimizer.zero_grad()

    # å‰å‘ä¼ æ’­
    outputs = model(X_train_tensor)
    torque_pred, speed_pred = outputs[:, 0], outputs[:, 1]

    # æ•°æ®æŸå¤±ï¼ˆMSEï¼‰
    data_loss = mse_loss(outputs, y_train_tensor)

    # æå–è¾“å…¥ä¸­çš„ç”µæµ
    iq = X_train_tensor[:, 0]

    # æå–çœŸå®çš„è´Ÿè½½æ‰­çŸ© (å‡è®¾ 'torque' æ˜¯è´Ÿè½½æ‰­çŸ©)
    T_load = y_train_tensor[:, 0]

    # æ‰­çŸ©æ–¹ç¨‹æ®‹å·®ï¼šT_pred = K_t * i_q
    res_torque = torque_pred - (K_t * iq)

    # é€Ÿåº¦åŠ¨æ€æ–¹ç¨‹æ®‹å·®ï¼šT_pred = T_loadï¼ˆç¨³æ€æ¡ä»¶ä¸‹ï¼‰
    res_speed = torque_pred - T_load

    # ç‰©ç†æŸå¤±
    phys_loss = torch.mean(res_torque**2) + torch.mean(res_speed**2)  # é€Ÿåº¦åŠ¨æ€æ–¹ç¨‹æ®‹å·®
    # phys_loss = torch.mean(res_torque ** 2)  # ä»…è€ƒè™‘æ‰­çŸ©æ–¹ç¨‹æ®‹å·®

    # æ€»æŸå¤±
    total_loss = data_loss + lambda_phys * phys_loss

    # åå‘ä¼ æ’­å’Œä¼˜åŒ–
    total_loss.backward()
    optimizer.step()

    # æ¯10ä¸ªepochæ‰“å°ä¸€æ¬¡æŸå¤±
    if (epoch + 1) % 10 == 0:
        print(f'Epoch [{epoch + 1}/{num_epochs}], Data Loss: {data_loss.item():.6f}, '
              f'Physical Loss: {phys_loss.item():.6f}, Total Loss: {total_loss.item():.6f}')

# è¯„ä¼°æ¨¡å‹
model.eval()
with torch.no_grad():
    test_outputs = model(X_test_tensor)
    test_loss = mse_loss(test_outputs, y_test_tensor)
    print(f'\nTest Loss: {test_loss.item():.6f}')

    # åå½’ä¸€åŒ–é¢„æµ‹å€¼å’ŒçœŸå®å€¼
    y_pred = scaler_y.inverse_transform(test_outputs.numpy())
    y_true = scaler_y.inverse_transform(y_test_tensor.numpy())

    # è®¡ç®—MSEå’ŒRÂ²åˆ†æ•°
    mse = mean_squared_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)

    print(f'Test Mean Squared Error: {mse:.6f}')
    print(f'Test R^2 Score: {r2:.6f}')

    # è®¡ç®—æ®‹å·®
    residuals = np.abs(y_true - y_pred)

    # ç»˜åˆ¶æ®‹å·®åˆ†å¸ƒå›¾
    plt.figure(figsize=(12, 6))
    plt.hist(residuals.flatten(), bins=50, edgecolor='k', alpha=0.7)
    plt.xlabel('Residuals')
    plt.ylabel('Frequency')
    plt.title('Residuals Distribution')
    plt.show()
```

```
Epoch [950/1000], Data Loss: 0.077357, Physical Loss: 1.089441, Total Loss: 0.078446
Epoch [960/1000], Data Loss: 0.077187, Physical Loss: 1.090424, Total Loss: 0.078278
Epoch [970/1000], Data Loss: 0.076989, Physical Loss: 1.090475, Total Loss: 0.078080
Epoch [980/1000], Data Loss: 0.076832, Physical Loss: 1.087985, Total Loss: 0.077920
Epoch [990/1000], Data Loss: 0.076586, Physical Loss: 1.089882, Total Loss: 0.077676
Epoch [1000/1000], Data Loss: 0.076360, Physical Loss: 1.089078, Total Loss: 0.077449

Test Loss: 0.215963
Test Mean Squared Error: 3609.480957
Test R^2 Score: 0.451778

```

è®­ç»ƒæ•ˆæœä¸å¥½ï¼Œæ²¡æœ‰åŸæ¥çš„å¥½
åˆ†æï¼šæ ¹æ®å…¬å¼ï¼Œæ‰­çŸ©åº”è¯¥ä¸iqæ­£ç›¸å…³ï¼Œè€Œiqä¸€ç›´ä¸Šä¸‹æ³¢åŠ¨ï¼Œæ‰­çŸ©å˜åŒ–ä¸å¤§ï¼Œå¯¼è‡´ç‰©ç†æŸå¤±æœ‰é—®é¢˜ï¼Œè€ƒè™‘å°†å‰ä¸€æ®µæ—¶é—´çš„æ•°æ®çº³å…¥ç»Ÿè®¡

## åˆ†ææ—¶é—´ç›¸å…³ç¥ç»ç½‘ç»œ
å¦‚æœç¥ç»ç½‘ç»œçš„è¾“å‡ºå’Œæ—¶é—´æœ‰å…³ï¼Œè¯´æ˜ä½ çš„é—®é¢˜æ¶‰åŠæ—¶é—´åºåˆ—æˆ–åŠ¨æ€å˜åŒ–çš„ç‰¹æ€§ã€‚ä¸ºäº†æ•æ‰æ—¶é—´ç›¸å…³æ€§ï¼Œéœ€è¦è®¾è®¡èƒ½å¤Ÿå¤„ç†æ—¶é—´ä¾èµ–çš„ç½‘ç»œç»“æ„ï¼Œä¾‹å¦‚ï¼š


### 1. **å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNN, LSTM, GRUï¼‰**
   - **RNNï¼ˆRecurrent Neural Networksï¼‰**: ç”¨äºæ•è·æ—¶é—´åºåˆ—ä¸­çš„ä¾èµ–å…³ç³»ï¼Œå…¶è¾“å‡ºä¼šåŸºäºå½“å‰è¾“å…¥å’Œä¹‹å‰çš„éšè—çŠ¶æ€ã€‚é€‚ç”¨äºçŸ­æœŸä¾èµ–é—®é¢˜ã€‚
   - **LSTMï¼ˆLong Short-Term Memoryï¼‰**: æ˜¯ä¸€ç§æ”¹è¿›çš„ RNNï¼Œèƒ½å¤Ÿæ•è·é•¿æœŸä¾èµ–å…³ç³»ï¼Œé€‚ç”¨äºæ›´å¤æ‚çš„æ—¶é—´åºåˆ—ä»»åŠ¡ã€‚
   - **GRUï¼ˆGated Recurrent Unitï¼‰**: æ˜¯ LSTM çš„ä¸€ç§ç®€åŒ–ç‰ˆæœ¬ï¼Œè®¡ç®—æ•ˆç‡æ›´é«˜ï¼Œæ•ˆæœå’Œ LSTM æ¥è¿‘ã€‚

   **ä¼˜ç‚¹**: é€‚åˆå¤„ç†è¿ç»­æ—¶é—´åºåˆ—æ•°æ®ã€‚
   **ç¼ºç‚¹**: éšç€åºåˆ—é•¿åº¦å¢åŠ ï¼Œå¯èƒ½å‡ºç°æ¢¯åº¦æ¶ˆå¤±æˆ–çˆ†ç‚¸é—®é¢˜ã€‚


### 2. **ä¸€ç»´å·ç§¯ç¥ç»ç½‘ç»œï¼ˆ1D-CNNï¼‰**
   - é€šè¿‡å·ç§¯æ“ä½œå¤„ç†æ—¶é—´åºåˆ—æ•°æ®ï¼Œæå–å±€éƒ¨çš„æ—¶é—´ç›¸å…³æ¨¡å¼ã€‚
   - é€šå¸¸é€‚åˆç”¨äºå›ºå®šé•¿åº¦çš„æ—¶é—´çª—å£åˆ†æï¼Œè®¡ç®—æ•ˆç‡é«˜ã€‚

   **ä¼˜ç‚¹**: æ¯” RNN çš„è®­ç»ƒé€Ÿåº¦å¿«ï¼Œé€‚åˆå¹³è¡ŒåŒ–å¤„ç†ã€‚
   **ç¼ºç‚¹**: å¯¹é•¿æ—¶é—´ä¾èµ–å»ºæ¨¡èƒ½åŠ›è¾ƒå¼±ã€‚

### 3. **Transformer**
   - **åŸºäºæ³¨æ„åŠ›æœºåˆ¶**ï¼Œèƒ½å¤Ÿæ•æ‰åºåˆ—ä¸­çš„å…¨å±€ä¾èµ–å…³ç³»ï¼Œæ— éœ€åƒ RNN é‚£æ ·é€æ­¥å¤„ç†ã€‚
   - **æ—¶é—´åºåˆ— Transformerï¼ˆTime-Series Transformerï¼‰**: ç‰¹åˆ«é€‚ç”¨äºé•¿æ—¶é—´åºåˆ—é¢„æµ‹ã€‚
   - **ä¼˜ç‚¹**: è®¡ç®—æ•ˆç‡é«˜ï¼Œå°¤å…¶é€‚åˆé•¿åºåˆ—ã€‚
   - **ç¼ºç‚¹**: å¯¹å°è§„æ¨¡æ•°æ®å¯èƒ½è¡¨ç°ä¸ä½³ã€‚


### 4. **ç‰©ç†ä¿¡æ¯åµŒå…¥ï¼ˆPhysics-Informed Neural Networks, PINNsï¼‰**
   - å¦‚æœä½ çš„æ—¶é—´åºåˆ—æ•°æ®å…·æœ‰ç‰©ç†èƒŒæ™¯ï¼Œå¯ä»¥é€šè¿‡ PINNs å°†ç‰©ç†å¾®åˆ†æ–¹ç¨‹ï¼ˆå¦‚æ—¶é—´ç›¸å…³çš„åŠ¨åŠ›å­¦æ–¹ç¨‹ï¼‰èå…¥ç¥ç»ç½‘ç»œã€‚
   - PINNs ä¼šç›´æ¥åœ¨ç½‘ç»œä¸­åµŒå…¥æ—¶é—´å˜é‡ \( t \)ï¼Œå¹¶çº¦æŸè¾“å‡ºæ»¡è¶³ç‰©ç†è§„å¾‹ã€‚
   - **ä¼˜ç‚¹**: èƒ½å¤Ÿæé«˜æ¨¡å‹çš„æ³›åŒ–æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯å¯¹æœªè§æ•°æ®æˆ–è¾¹ç•Œæ¡ä»¶çš„é¢„æµ‹ã€‚
   - **ç¼ºç‚¹**: éœ€è¦æ˜ç¡®çš„ç‰©ç†è§„å¾‹ä½œä¸ºå…ˆéªŒä¿¡æ¯ã€‚


### æ—¶é—´ç›¸å…³æ€§å»ºæ¨¡çš„è¾“å…¥è®¾è®¡
1. **æ˜¾å¼åŠ å…¥æ—¶é—´å˜é‡**:
   - ç›´æ¥å°†æ—¶é—´ \( t \) ä½œä¸ºç½‘ç»œçš„ä¸€ä¸ªè¾“å…¥ç»´åº¦ï¼Œæ¨¡å‹çš„è¾“å‡º \( y \) ä¾èµ–äº \( t \)ï¼š  
     \[
     y = f(x, t)
     \]  

2. **æ—¶é—´çª—å£æ»‘åŠ¨**:
   - æå–å›ºå®šé•¿åº¦çš„æ—¶é—´çª—å£æ•°æ®ä½œä¸ºè¾“å…¥ï¼Œä¾‹å¦‚ ( [x_{t-3}, x_{t-2}, x_{t-1}, x_t] ï¼‰ é¢„æµ‹ ( x_{t+1} )ã€‚

3. **æ—¶é—´åºåˆ—åµŒå…¥**:
   - å°†æ—¶é—´åºåˆ—æ•°æ®é€šè¿‡ç‰¹å¾æå–ç½‘ç»œï¼ˆå¦‚ LSTM æˆ– Transformer ç¼–ç å™¨ï¼‰è½¬æ¢ä¸ºéšå«ç‰¹å¾ï¼Œå†è¿›è¡Œåç»­é¢„æµ‹ã€‚


## ä½¿ç”¨CNN1Dï¼ˆä¸€ç»´å·ç§¯ç¥ç»ç½‘ç»œï¼‰

è¾“å…¥æ—¶é—´çª—å£æ»‘åŠ¨ï¼Œè¯•ç€ä¼˜åŒ–æ¨¡å‹

```python
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Step 1: Load the dataset
df = pd.read_csv('data/merged.csv')

# Step 2: Generate time step feature (assuming data is sorted by 'unique_time')
df['time_step'] = np.arange(len(df)) * 0.1  # æ¯ä¸€æ­¥ 0.1s çš„å›ºå®šæ—¶é—´é—´éš”

# Features and targets
features = ['iq', 'id', 'vd', 'vq', 'time_step']
target = ['torque', 'speed']

# Step 3: Normalize the features and targets
X = df[features].values
y = df[target].values

scaler_X = StandardScaler()
scaler_y = StandardScaler()

X = scaler_X.fit_transform(X)
y = scaler_y.fit_transform(y)

# Step 4: Sliding window for time series data
def create_sliding_window(data, target, window_size):
    """
    Creates sliding window data for time series modeling.

    Args:
        data (np.array): Feature data.
        target (np.array): Target data.
        window_size (int): Number of time steps in the window.

    Returns:
        X, y: Features and targets for the model.
    """
    X_window, y_window = [], []
    for i in range(len(data) - window_size):
        X_window.append(data[i:i + window_size])  # Use the past `window_size` steps
        y_window.append(target[i + window_size])  # Predict the next time step's target
    return np.array(X_window), np.array(y_window)

# Parameters
window_size = 10  # Use the past 10 time steps

# Prepare data
X_window, y_window = create_sliding_window(X, y, window_size)

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X_window, y_window, test_size=0.2, random_state=42)

# Reshape for 1D-CNN (samples, channels, sequence_length)
X_train = X_train.transpose(0, 2, 1)  # Shape: (samples, channels, sequence_length)
X_test = X_test.transpose(0, 2, 1)

# Convert to PyTorch tensors
X_train = torch.tensor(X_train, dtype=torch.float32)
X_test = torch.tensor(X_test, dtype=torch.float32)
y_train = torch.tensor(y_train, dtype=torch.float32)
y_test = torch.tensor(y_test, dtype=torch.float32)

# Step 5: Define the 1D-CNN model
class CNN1D(nn.Module):
    def __init__(self):
        super(CNN1D, self).__init__()
        self.conv1 = nn.Conv1d(in_channels=len(features), out_channels=16, kernel_size=3, stride=1, padding=1)
        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)
        self.fc1 = nn.Linear(32 * window_size, 64)
        self.fc2 = nn.Linear(64, len(target))
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.2)

    def forward(self, x):
        x = self.conv1(x)
        x = self.relu(x)
        x = self.conv2(x)
        x = self.relu(x)
        x = x.view(x.size(0), -1)  # Flatten for fully connected layers
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        return x

# Step 6: Initialize model, loss, and optimizer
model = CNN1D()
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Step 7: Train the model
epochs = 200
for epoch in range(epochs):
    model.train()
    optimizer.zero_grad()
    outputs = model(X_train)
    loss = criterion(outputs, y_train)
    loss.backward()
    optimizer.step()

    # Evaluate on test set
    model.eval()
    with torch.no_grad():
        test_outputs = model(X_test)
        test_loss = criterion(test_outputs, y_test)

    print(f"Epoch {epoch+1}/{epochs}, Train Loss: {loss.item():.4f}, Test Loss: {test_loss.item():.4f}")

# Step 8: Final evaluation
#model.eval()
#with torch.no_grad():
#    predictions = model(X_test)
#    mse = criterion(predictions, y_test).item()
#    print(f"Final Test MSE: {mse:.4f}")
#
## Step 9: Inverse transform the predictions (optional)
#predictions = scaler_y.inverse_transform(predictions.numpy())
#y_test = scaler_y.inverse_transform(y_test.numpy())

from sklearn.metrics import r2_score


# Step 8: Final evaluation
model.eval()
with torch.no_grad():
    predictions = model(X_test)
    mse = criterion(predictions, y_test).item()

    # Convert to NumPy arrays for R^2 calculation
    predictions_np = predictions.numpy()
    y_test_np = y_test.numpy()

    # Calculate R^2
    r2 = r2_score(y_test_np, predictions_np)

print(f"Final Test MSE: {mse:.4f}")
print(f"Final Test R^2 Score: {r2:.4f}")

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.hist(y_train.numpy().flatten(), bins=30, alpha=0.7, label='Train')
plt.hist(y_test.numpy().flatten(), bins=30, alpha=0.7, label='Test')
plt.legend()
plt.title("Distribution of Target Values")
plt.subplot(1, 2, 2)
plt.boxplot([y_train.numpy().flatten(), y_test.numpy().flatten()], labels=["Train", "Test"])
plt.title("Boxplot of Target Values")
plt.show()
```

```
Epoch 1/200, Train Loss: 0.9145, Test Loss: 0.4756
Epoch 2/200, Train Loss: 0.8898, Test Loss: 0.4527
Epoch 3/200, Train Loss: 0.8612, Test Loss: 0.4292
Epoch 4/200, Train Loss: 0.8357, Test Loss: 0.4053
...
Epoch 199/200, Train Loss: 0.0170, Test Loss: 0.0071
Epoch 200/200, Train Loss: 0.0214, Test Loss: 0.0072
Final Test MSE: 0.0072
Final Test R^2 Score: -16.4196
```

å¯ä»¥çœ‹å‡ºï¼ŒæŸå¤±ç›´æ¥å°äº†å¾ˆå¤šï¼ŒMSEä¹Ÿå¾ˆå°ï¼Œä½†æ˜¯R2åˆ†æ•°è´Ÿæ•°ï¼Œåˆ†æé—®é¢˜

![image](https://github.com/user-attachments/assets/b2239a3d-d951-41d6-860c-d329b2ed195b)

å¯èƒ½åŸå› åˆ†æ
æµ‹è¯•é›†æ•°æ®åˆ†å¸ƒé—®é¢˜ï¼š

å¦‚æœæµ‹è¯•é›†ä¸è®­ç»ƒé›†çš„åˆ†å¸ƒå·®å¼‚è¿‡å¤§ï¼ˆä¾‹å¦‚ï¼Œæ•°æ®åç§»æˆ–ä¸å‡è¡¡ï¼‰ï¼Œæ¨¡å‹å¯èƒ½æ— æ³•åœ¨æµ‹è¯•é›†ä¸Šç”Ÿæˆåˆç†çš„é¢„æµ‹ç»“æœã€‚
æ•°æ®æ³„æ¼æˆ–æ ‡ç­¾é—®é¢˜ï¼š

æ£€æŸ¥æ•°æ®é¢„å¤„ç†å’Œæ»‘åŠ¨çª—å£çš„å®ç°ï¼Œç¡®ä¿æµ‹è¯•é›†çš„ç›®æ ‡å˜é‡æ²¡æœ‰è¢«è®­ç»ƒæ•°æ®æå‰æ³„éœ²ã€‚
æ£€æŸ¥æ•°æ®ä¸­çš„ç›®æ ‡å€¼ï¼ˆtorque å’Œ speedï¼‰ï¼Œç¡®è®¤æ˜¯å¦å­˜åœ¨å¼‚å¸¸å€¼æˆ–é”™è¯¯æ ‡æ³¨ã€‚
æ¨¡å‹è¿‡æ‹Ÿåˆï¼š

å°½ç®¡ Train Loss å’Œ Test Loss éƒ½å¾ˆä½ï¼Œæ¨¡å‹å¯èƒ½è¿‡åº¦æ‹Ÿåˆè®­ç»ƒé›†ï¼Œè€Œæœªå­¦åˆ°æµ‹è¯•é›†çš„é€šç”¨æ¨¡å¼ã€‚
æ£€æŸ¥æ¨¡å‹çš„å¤æ‚åº¦å’Œæ­£åˆ™åŒ–ï¼ˆå¦‚ Dropout çš„ä½¿ç”¨ï¼‰ã€‚

è¯„ä»·æŒ‡æ ‡é—®é¢˜ï¼š
ğ‘…2è®¡ç®—ä¸­ï¼Œç›®æ ‡å€¼çš„åˆ†å¸ƒéå¸¸é›†ä¸­æˆ–æœ‰æç«¯å€¼æ—¶ï¼ŒSS_totä¼šå˜å¾—éå¸¸å°ï¼Œå¯¼è‡´ ğ‘…2å¼‚å¸¸ã€‚

åº”è¯¥æ˜¯è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†åˆ’åˆ†æœ‰é—®é¢˜ï¼Œè®­ç»ƒæ•°æ®é›†å–äº†80%,æµ‹è¯•20%ï¼Œè®­ç»ƒé›†åŒ…å«å¯åŠ¨çš„éƒ¨åˆ†ï¼Œè€Œæµ‹è¯•é›†åªåŒ…å«äº†ç¨³å®šè¿è¡Œçš„éƒ¨åˆ†ï¼ˆä¸‹ä¸€æ­¥å‡†å¤‡å¢åŠ æ•°æ®ï¼Œå°†å¯åŠ¨å’Œåœæ­¢éƒ¨åˆ†åŠ ä¸Šå»ï¼‰





